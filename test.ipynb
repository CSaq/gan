{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# 创建文件夹\n",
    "os.makedirs(\"./images/gan/\", exist_ok=True)  # 保存训练过程的图片\n",
    "os.makedirs(\"./save/gan/\", exist_ok=True)  # 训练完成时模型保存的位置\n",
    "os.makedirs(\"./datasets/mnist\", exist_ok=True)  # 下载数据集存放的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "img_size = 28\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 图像的尺寸:(1， 28， 28),  和图像的像素面积:(784)\n",
    "img_shape = (channels, img_size, img_size)\n",
    "img_area = np.prod(img_shape)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print('cuda:', cuda)\n",
    "\n",
    "# mnist数据集下载\n",
    "mnist = datasets.MNIST(\n",
    "    root='./datasets/', train=True, download=True, transform=transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize([0.5], [0.5])]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器 Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_area, 512),  # 输入特征数为784\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "\n",
    "# 定义生成器 Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # 模型中间块儿\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, img_area),\n",
    "            nn.Tanh()  # 将(784)的数据每一个都映射到[-1, 1]之间\n",
    "        )\n",
    "\n",
    "    def forward(self, z):  # 输入的是(64， 100)的噪声数据\n",
    "        imgs = self.model(z)  # 噪声数据通过生成器模型\n",
    "        imgs = imgs.view(imgs.size(0), *img_shape)\n",
    "        return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建生成器，判别器对象\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# 其次定义 优化函数,优化函数的学习率为0.0003\n",
    "# betas:用于计算梯度以及梯度平方的运行平均值的系数\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# 如果有显卡，都在cuda模式中运行\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [Batch 99/938] [D loss: 1.314692] [G loss: 0.664975] [D real: 0.587226] [D fake: 0.515453]\n",
      "[Epoch 0/50] [Batch 199/938] [D loss: 1.085302] [G loss: 1.073382] [D real: 0.659144] [D fake: 0.483829]\n",
      "[Epoch 0/50] [Batch 299/938] [D loss: 1.169366] [G loss: 0.688896] [D real: 0.482463] [D fake: 0.332062]\n",
      "[Epoch 0/50] [Batch 399/938] [D loss: 1.033351] [G loss: 1.379799] [D real: 0.632202] [D fake: 0.420711]\n",
      "[Epoch 0/50] [Batch 499/938] [D loss: 1.073791] [G loss: 1.228435] [D real: 0.758415] [D fake: 0.538224]\n",
      "[Epoch 0/50] [Batch 599/938] [D loss: 1.095375] [G loss: 0.857327] [D real: 0.535340] [D fake: 0.319981]\n",
      "[Epoch 0/50] [Batch 699/938] [D loss: 0.921353] [G loss: 1.397030] [D real: 0.681502] [D fake: 0.387700]\n",
      "[Epoch 0/50] [Batch 799/938] [D loss: 1.012501] [G loss: 0.808668] [D real: 0.480912] [D fake: 0.199825]\n",
      "[Epoch 0/50] [Batch 899/938] [D loss: 1.112474] [G loss: 1.684664] [D real: 0.821570] [D fake: 0.587232]\n",
      "[Epoch 1/50] [Batch 99/938] [D loss: 0.803504] [G loss: 2.170812] [D real: 0.817673] [D fake: 0.432539]\n",
      "[Epoch 1/50] [Batch 199/938] [D loss: 0.840987] [G loss: 1.435674] [D real: 0.629989] [D fake: 0.269379]\n",
      "[Epoch 1/50] [Batch 299/938] [D loss: 0.870025] [G loss: 1.305677] [D real: 0.663524] [D fake: 0.320480]\n",
      "[Epoch 1/50] [Batch 399/938] [D loss: 1.146861] [G loss: 1.877801] [D real: 0.781312] [D fake: 0.575056]\n",
      "[Epoch 1/50] [Batch 499/938] [D loss: 0.801041] [G loss: 1.608416] [D real: 0.772552] [D fake: 0.394008]\n",
      "[Epoch 1/50] [Batch 599/938] [D loss: 1.162850] [G loss: 2.330864] [D real: 0.846941] [D fake: 0.607113]\n",
      "[Epoch 1/50] [Batch 699/938] [D loss: 0.629924] [G loss: 1.940953] [D real: 0.764753] [D fake: 0.274341]\n",
      "[Epoch 1/50] [Batch 799/938] [D loss: 0.998433] [G loss: 0.921050] [D real: 0.573468] [D fake: 0.289461]\n",
      "[Epoch 1/50] [Batch 899/938] [D loss: 0.769455] [G loss: 1.557212] [D real: 0.759970] [D fake: 0.363839]\n",
      "[Epoch 2/50] [Batch 99/938] [D loss: 0.940762] [G loss: 2.910439] [D real: 0.852561] [D fake: 0.515807]\n",
      "[Epoch 2/50] [Batch 199/938] [D loss: 0.937543] [G loss: 1.167608] [D real: 0.611315] [D fake: 0.292232]\n",
      "[Epoch 2/50] [Batch 299/938] [D loss: 1.070404] [G loss: 0.626244] [D real: 0.486799] [D fake: 0.128878]\n",
      "[Epoch 2/50] [Batch 399/938] [D loss: 0.925029] [G loss: 1.130890] [D real: 0.569055] [D fake: 0.208305]\n",
      "[Epoch 2/50] [Batch 499/938] [D loss: 0.952786] [G loss: 1.223664] [D real: 0.629528] [D fake: 0.315202]\n",
      "[Epoch 2/50] [Batch 599/938] [D loss: 0.810273] [G loss: 1.410203] [D real: 0.688093] [D fake: 0.301765]\n",
      "[Epoch 2/50] [Batch 699/938] [D loss: 1.299819] [G loss: 0.802468] [D real: 0.465277] [D fake: 0.289666]\n",
      "[Epoch 2/50] [Batch 799/938] [D loss: 1.116924] [G loss: 1.149817] [D real: 0.519144] [D fake: 0.110638]\n",
      "[Epoch 2/50] [Batch 899/938] [D loss: 1.020639] [G loss: 2.477505] [D real: 0.757552] [D fake: 0.480207]\n",
      "[Epoch 3/50] [Batch 99/938] [D loss: 0.875630] [G loss: 1.465934] [D real: 0.676785] [D fake: 0.333047]\n",
      "[Epoch 3/50] [Batch 199/938] [D loss: 0.705055] [G loss: 1.094777] [D real: 0.698946] [D fake: 0.232672]\n",
      "[Epoch 3/50] [Batch 299/938] [D loss: 1.223355] [G loss: 2.970619] [D real: 0.853035] [D fake: 0.627183]\n",
      "[Epoch 3/50] [Batch 399/938] [D loss: 0.908947] [G loss: 1.225056] [D real: 0.611223] [D fake: 0.197810]\n",
      "[Epoch 3/50] [Batch 499/938] [D loss: 0.949410] [G loss: 0.737620] [D real: 0.509611] [D fake: 0.107284]\n",
      "[Epoch 3/50] [Batch 599/938] [D loss: 0.882560] [G loss: 1.559362] [D real: 0.740885] [D fake: 0.354669]\n",
      "[Epoch 3/50] [Batch 699/938] [D loss: 0.768857] [G loss: 1.812867] [D real: 0.727857] [D fake: 0.298781]\n",
      "[Epoch 3/50] [Batch 799/938] [D loss: 0.938474] [G loss: 1.224729] [D real: 0.680555] [D fake: 0.358115]\n",
      "[Epoch 3/50] [Batch 899/938] [D loss: 0.706520] [G loss: 1.629502] [D real: 0.726089] [D fake: 0.242985]\n",
      "[Epoch 4/50] [Batch 99/938] [D loss: 0.744403] [G loss: 1.753647] [D real: 0.661833] [D fake: 0.190516]\n",
      "[Epoch 4/50] [Batch 199/938] [D loss: 0.781190] [G loss: 1.571160] [D real: 0.668698] [D fake: 0.203981]\n",
      "[Epoch 4/50] [Batch 299/938] [D loss: 0.732241] [G loss: 1.858402] [D real: 0.711125] [D fake: 0.248719]\n",
      "[Epoch 4/50] [Batch 399/938] [D loss: 0.850407] [G loss: 1.760159] [D real: 0.826551] [D fake: 0.424952]\n",
      "[Epoch 4/50] [Batch 499/938] [D loss: 0.699936] [G loss: 2.124706] [D real: 0.812181] [D fake: 0.355075]\n",
      "[Epoch 4/50] [Batch 599/938] [D loss: 0.824477] [G loss: 2.201241] [D real: 0.844870] [D fake: 0.440414]\n",
      "[Epoch 4/50] [Batch 699/938] [D loss: 1.332647] [G loss: 0.632904] [D real: 0.411544] [D fake: 0.065448]\n",
      "[Epoch 4/50] [Batch 799/938] [D loss: 0.824550] [G loss: 2.030514] [D real: 0.765362] [D fake: 0.363089]\n",
      "[Epoch 4/50] [Batch 899/938] [D loss: 0.796710] [G loss: 1.521386] [D real: 0.701177] [D fake: 0.300534]\n",
      "[Epoch 5/50] [Batch 99/938] [D loss: 0.828024] [G loss: 1.361951] [D real: 0.705164] [D fake: 0.297938]\n",
      "[Epoch 5/50] [Batch 199/938] [D loss: 0.807596] [G loss: 1.377595] [D real: 0.647411] [D fake: 0.207282]\n",
      "[Epoch 5/50] [Batch 299/938] [D loss: 0.730868] [G loss: 2.331401] [D real: 0.751254] [D fake: 0.297562]\n",
      "[Epoch 5/50] [Batch 399/938] [D loss: 0.861896] [G loss: 1.689282] [D real: 0.689078] [D fake: 0.283575]\n",
      "[Epoch 5/50] [Batch 499/938] [D loss: 0.835105] [G loss: 1.740249] [D real: 0.736659] [D fake: 0.358091]\n",
      "[Epoch 5/50] [Batch 599/938] [D loss: 1.129951] [G loss: 0.791255] [D real: 0.459241] [D fake: 0.127752]\n",
      "[Epoch 5/50] [Batch 699/938] [D loss: 0.926391] [G loss: 1.160370] [D real: 0.573650] [D fake: 0.159154]\n",
      "[Epoch 5/50] [Batch 799/938] [D loss: 1.033665] [G loss: 1.323352] [D real: 0.596269] [D fake: 0.214259]\n",
      "[Epoch 5/50] [Batch 899/938] [D loss: 0.888134] [G loss: 1.708951] [D real: 0.747694] [D fake: 0.399211]\n",
      "[Epoch 6/50] [Batch 99/938] [D loss: 0.779136] [G loss: 2.195841] [D real: 0.797775] [D fake: 0.388680]\n",
      "[Epoch 6/50] [Batch 199/938] [D loss: 0.757769] [G loss: 1.636950] [D real: 0.724096] [D fake: 0.294191]\n",
      "[Epoch 6/50] [Batch 299/938] [D loss: 1.042635] [G loss: 0.953732] [D real: 0.534252] [D fake: 0.115636]\n",
      "[Epoch 6/50] [Batch 399/938] [D loss: 0.759982] [G loss: 1.284791] [D real: 0.708076] [D fake: 0.271389]\n",
      "[Epoch 6/50] [Batch 499/938] [D loss: 0.859542] [G loss: 0.999416] [D real: 0.574542] [D fake: 0.115916]\n",
      "[Epoch 6/50] [Batch 599/938] [D loss: 1.161950] [G loss: 0.747428] [D real: 0.484436] [D fake: 0.154182]\n",
      "[Epoch 6/50] [Batch 699/938] [D loss: 0.974124] [G loss: 1.106282] [D real: 0.681279] [D fake: 0.335894]\n",
      "[Epoch 6/50] [Batch 799/938] [D loss: 0.999827] [G loss: 0.952868] [D real: 0.568905] [D fake: 0.242590]\n",
      "[Epoch 6/50] [Batch 899/938] [D loss: 1.014318] [G loss: 2.309629] [D real: 0.825324] [D fake: 0.511734]\n",
      "[Epoch 7/50] [Batch 99/938] [D loss: 0.845217] [G loss: 2.329346] [D real: 0.801674] [D fake: 0.407805]\n",
      "[Epoch 7/50] [Batch 199/938] [D loss: 0.811203] [G loss: 0.975195] [D real: 0.627116] [D fake: 0.197536]\n",
      "[Epoch 7/50] [Batch 299/938] [D loss: 0.959365] [G loss: 1.928000] [D real: 0.774440] [D fake: 0.431066]\n",
      "[Epoch 7/50] [Batch 399/938] [D loss: 0.770693] [G loss: 2.263523] [D real: 0.802293] [D fake: 0.385625]\n",
      "[Epoch 7/50] [Batch 499/938] [D loss: 0.944540] [G loss: 0.789606] [D real: 0.574060] [D fake: 0.152025]\n",
      "[Epoch 7/50] [Batch 599/938] [D loss: 0.803927] [G loss: 1.803461] [D real: 0.742913] [D fake: 0.329282]\n",
      "[Epoch 7/50] [Batch 699/938] [D loss: 0.765944] [G loss: 1.092401] [D real: 0.638125] [D fake: 0.172898]\n",
      "[Epoch 7/50] [Batch 799/938] [D loss: 0.838915] [G loss: 2.129460] [D real: 0.755596] [D fake: 0.374220]\n",
      "[Epoch 7/50] [Batch 899/938] [D loss: 1.020358] [G loss: 1.299230] [D real: 0.710020] [D fake: 0.392773]\n",
      "[Epoch 8/50] [Batch 99/938] [D loss: 0.812849] [G loss: 1.541173] [D real: 0.720648] [D fake: 0.301343]\n",
      "[Epoch 8/50] [Batch 199/938] [D loss: 0.924954] [G loss: 1.451305] [D real: 0.641732] [D fake: 0.299519]\n",
      "[Epoch 8/50] [Batch 299/938] [D loss: 1.126418] [G loss: 2.695184] [D real: 0.841764] [D fake: 0.569521]\n",
      "[Epoch 8/50] [Batch 399/938] [D loss: 0.915804] [G loss: 2.031349] [D real: 0.757098] [D fake: 0.400439]\n",
      "[Epoch 8/50] [Batch 499/938] [D loss: 0.915263] [G loss: 2.471202] [D real: 0.837990] [D fake: 0.487039]\n",
      "[Epoch 8/50] [Batch 599/938] [D loss: 0.939323] [G loss: 0.824658] [D real: 0.600273] [D fake: 0.200104]\n",
      "[Epoch 8/50] [Batch 699/938] [D loss: 1.034945] [G loss: 2.210836] [D real: 0.750066] [D fake: 0.463565]\n",
      "[Epoch 8/50] [Batch 799/938] [D loss: 0.839827] [G loss: 1.256861] [D real: 0.652111] [D fake: 0.229561]\n",
      "[Epoch 8/50] [Batch 899/938] [D loss: 0.976788] [G loss: 1.460120] [D real: 0.560127] [D fake: 0.137222]\n",
      "[Epoch 9/50] [Batch 99/938] [D loss: 0.836260] [G loss: 1.569490] [D real: 0.757795] [D fake: 0.370928]\n",
      "[Epoch 9/50] [Batch 199/938] [D loss: 1.489242] [G loss: 0.641689] [D real: 0.369688] [D fake: 0.089678]\n",
      "[Epoch 9/50] [Batch 299/938] [D loss: 0.912226] [G loss: 1.261124] [D real: 0.706048] [D fake: 0.347037]\n",
      "[Epoch 9/50] [Batch 399/938] [D loss: 0.843205] [G loss: 1.341533] [D real: 0.689930] [D fake: 0.291849]\n",
      "[Epoch 9/50] [Batch 499/938] [D loss: 1.036558] [G loss: 1.956674] [D real: 0.812118] [D fake: 0.510168]\n",
      "[Epoch 9/50] [Batch 599/938] [D loss: 0.896388] [G loss: 1.704609] [D real: 0.796055] [D fake: 0.426688]\n",
      "[Epoch 9/50] [Batch 699/938] [D loss: 1.110781] [G loss: 1.113213] [D real: 0.553418] [D fake: 0.200882]\n",
      "[Epoch 9/50] [Batch 799/938] [D loss: 1.050100] [G loss: 1.608118] [D real: 0.658998] [D fake: 0.403626]\n",
      "[Epoch 9/50] [Batch 899/938] [D loss: 0.891811] [G loss: 1.545792] [D real: 0.704171] [D fake: 0.328425]\n",
      "[Epoch 10/50] [Batch 99/938] [D loss: 0.906895] [G loss: 1.969361] [D real: 0.819366] [D fake: 0.452223]\n",
      "[Epoch 10/50] [Batch 199/938] [D loss: 0.859617] [G loss: 1.706153] [D real: 0.770061] [D fake: 0.378773]\n",
      "[Epoch 10/50] [Batch 299/938] [D loss: 0.822858] [G loss: 1.523528] [D real: 0.656865] [D fake: 0.254389]\n",
      "[Epoch 10/50] [Batch 399/938] [D loss: 0.880292] [G loss: 1.363115] [D real: 0.677456] [D fake: 0.318372]\n",
      "[Epoch 10/50] [Batch 499/938] [D loss: 0.909403] [G loss: 2.019923] [D real: 0.780409] [D fake: 0.420856]\n",
      "[Epoch 10/50] [Batch 599/938] [D loss: 1.117853] [G loss: 2.124811] [D real: 0.845229] [D fake: 0.558817]\n",
      "[Epoch 10/50] [Batch 699/938] [D loss: 1.052777] [G loss: 0.849167] [D real: 0.529481] [D fake: 0.177575]\n",
      "[Epoch 10/50] [Batch 799/938] [D loss: 0.830373] [G loss: 1.498151] [D real: 0.773581] [D fake: 0.371211]\n",
      "[Epoch 10/50] [Batch 899/938] [D loss: 0.983429] [G loss: 1.636870] [D real: 0.735596] [D fake: 0.419529]\n",
      "[Epoch 11/50] [Batch 99/938] [D loss: 0.956717] [G loss: 1.783499] [D real: 0.747269] [D fake: 0.417326]\n",
      "[Epoch 11/50] [Batch 199/938] [D loss: 1.015168] [G loss: 0.912911] [D real: 0.516901] [D fake: 0.147242]\n",
      "[Epoch 11/50] [Batch 299/938] [D loss: 1.008703] [G loss: 1.337013] [D real: 0.683701] [D fake: 0.399232]\n",
      "[Epoch 11/50] [Batch 399/938] [D loss: 1.067089] [G loss: 0.604648] [D real: 0.485792] [D fake: 0.179220]\n",
      "[Epoch 11/50] [Batch 499/938] [D loss: 0.948205] [G loss: 0.952261] [D real: 0.592438] [D fake: 0.229627]\n",
      "[Epoch 11/50] [Batch 599/938] [D loss: 0.958508] [G loss: 1.542063] [D real: 0.771417] [D fake: 0.443903]\n",
      "[Epoch 11/50] [Batch 699/938] [D loss: 1.035953] [G loss: 1.030288] [D real: 0.609767] [D fake: 0.290915]\n",
      "[Epoch 11/50] [Batch 799/938] [D loss: 1.051119] [G loss: 1.270794] [D real: 0.677321] [D fake: 0.407126]\n",
      "[Epoch 11/50] [Batch 899/938] [D loss: 0.953687] [G loss: 1.240756] [D real: 0.714310] [D fake: 0.397040]\n",
      "[Epoch 12/50] [Batch 99/938] [D loss: 0.962709] [G loss: 1.053959] [D real: 0.649710] [D fake: 0.320647]\n",
      "[Epoch 12/50] [Batch 199/938] [D loss: 0.974666] [G loss: 2.083064] [D real: 0.834601] [D fake: 0.497174]\n",
      "[Epoch 12/50] [Batch 299/938] [D loss: 0.958501] [G loss: 1.350149] [D real: 0.617583] [D fake: 0.270083]\n",
      "[Epoch 12/50] [Batch 399/938] [D loss: 0.981132] [G loss: 1.059879] [D real: 0.619787] [D fake: 0.316580]\n",
      "[Epoch 12/50] [Batch 499/938] [D loss: 1.110107] [G loss: 0.950794] [D real: 0.498152] [D fake: 0.166130]\n",
      "[Epoch 12/50] [Batch 599/938] [D loss: 0.876982] [G loss: 1.944889] [D real: 0.777396] [D fake: 0.417644]\n",
      "[Epoch 12/50] [Batch 699/938] [D loss: 0.947292] [G loss: 1.693191] [D real: 0.767676] [D fake: 0.453380]\n",
      "[Epoch 12/50] [Batch 799/938] [D loss: 0.934388] [G loss: 1.198838] [D real: 0.619238] [D fake: 0.251416]\n",
      "[Epoch 12/50] [Batch 899/938] [D loss: 1.114438] [G loss: 0.857601] [D real: 0.507892] [D fake: 0.181363]\n",
      "[Epoch 13/50] [Batch 99/938] [D loss: 1.025048] [G loss: 0.865625] [D real: 0.546454] [D fake: 0.186601]\n",
      "[Epoch 13/50] [Batch 199/938] [D loss: 1.288269] [G loss: 2.262592] [D real: 0.856090] [D fake: 0.627120]\n",
      "[Epoch 13/50] [Batch 299/938] [D loss: 0.862777] [G loss: 1.192612] [D real: 0.682399] [D fake: 0.310177]\n",
      "[Epoch 13/50] [Batch 399/938] [D loss: 1.017034] [G loss: 0.789377] [D real: 0.537757] [D fake: 0.158811]\n",
      "[Epoch 13/50] [Batch 499/938] [D loss: 1.028340] [G loss: 1.035007] [D real: 0.630081] [D fake: 0.326159]\n",
      "[Epoch 13/50] [Batch 599/938] [D loss: 1.192384] [G loss: 2.302048] [D real: 0.861124] [D fake: 0.609914]\n",
      "[Epoch 13/50] [Batch 699/938] [D loss: 1.372917] [G loss: 0.499260] [D real: 0.386751] [D fake: 0.146639]\n",
      "[Epoch 13/50] [Batch 799/938] [D loss: 1.041826] [G loss: 1.185942] [D real: 0.649752] [D fake: 0.368035]\n",
      "[Epoch 13/50] [Batch 899/938] [D loss: 1.060080] [G loss: 1.361821] [D real: 0.637605] [D fake: 0.370205]\n",
      "[Epoch 14/50] [Batch 99/938] [D loss: 1.044054] [G loss: 1.979799] [D real: 0.793919] [D fake: 0.508810]\n",
      "[Epoch 14/50] [Batch 199/938] [D loss: 1.023556] [G loss: 0.740017] [D real: 0.519676] [D fake: 0.177337]\n",
      "[Epoch 14/50] [Batch 299/938] [D loss: 0.941174] [G loss: 0.910901] [D real: 0.620693] [D fake: 0.279009]\n",
      "[Epoch 14/50] [Batch 399/938] [D loss: 0.991468] [G loss: 2.203904] [D real: 0.830713] [D fake: 0.504317]\n",
      "[Epoch 14/50] [Batch 499/938] [D loss: 0.865782] [G loss: 1.602090] [D real: 0.694089] [D fake: 0.337048]\n",
      "[Epoch 14/50] [Batch 599/938] [D loss: 1.015676] [G loss: 1.239162] [D real: 0.516530] [D fake: 0.144487]\n",
      "[Epoch 14/50] [Batch 699/938] [D loss: 0.901727] [G loss: 0.918865] [D real: 0.607926] [D fake: 0.239398]\n",
      "[Epoch 14/50] [Batch 799/938] [D loss: 1.125630] [G loss: 2.132704] [D real: 0.762441] [D fake: 0.521257]\n",
      "[Epoch 14/50] [Batch 899/938] [D loss: 0.897540] [G loss: 1.184172] [D real: 0.607692] [D fake: 0.209172]\n",
      "[Epoch 15/50] [Batch 99/938] [D loss: 0.893758] [G loss: 1.861325] [D real: 0.766342] [D fake: 0.404822]\n",
      "[Epoch 15/50] [Batch 199/938] [D loss: 0.935216] [G loss: 1.809820] [D real: 0.761943] [D fake: 0.428993]\n",
      "[Epoch 15/50] [Batch 299/938] [D loss: 1.076958] [G loss: 1.703136] [D real: 0.732392] [D fake: 0.478579]\n",
      "[Epoch 15/50] [Batch 399/938] [D loss: 0.994758] [G loss: 0.768466] [D real: 0.525926] [D fake: 0.179372]\n",
      "[Epoch 15/50] [Batch 499/938] [D loss: 0.870902] [G loss: 1.389925] [D real: 0.628518] [D fake: 0.217237]\n",
      "[Epoch 15/50] [Batch 599/938] [D loss: 0.975248] [G loss: 1.492955] [D real: 0.663841] [D fake: 0.345778]\n",
      "[Epoch 15/50] [Batch 699/938] [D loss: 1.041877] [G loss: 2.137492] [D real: 0.778856] [D fake: 0.503154]\n",
      "[Epoch 15/50] [Batch 799/938] [D loss: 1.120757] [G loss: 1.111880] [D real: 0.535020] [D fake: 0.259046]\n",
      "[Epoch 15/50] [Batch 899/938] [D loss: 1.012942] [G loss: 1.802430] [D real: 0.719454] [D fake: 0.417269]\n",
      "[Epoch 16/50] [Batch 99/938] [D loss: 1.021014] [G loss: 1.423262] [D real: 0.755233] [D fake: 0.478874]\n",
      "[Epoch 16/50] [Batch 199/938] [D loss: 0.949662] [G loss: 1.581709] [D real: 0.687288] [D fake: 0.343380]\n",
      "[Epoch 16/50] [Batch 299/938] [D loss: 0.912223] [G loss: 0.905956] [D real: 0.624150] [D fake: 0.292378]\n",
      "[Epoch 16/50] [Batch 399/938] [D loss: 0.896143] [G loss: 1.389224] [D real: 0.683382] [D fake: 0.335364]\n",
      "[Epoch 16/50] [Batch 499/938] [D loss: 1.005388] [G loss: 1.489092] [D real: 0.705310] [D fake: 0.411035]\n",
      "[Epoch 16/50] [Batch 599/938] [D loss: 0.964189] [G loss: 1.069048] [D real: 0.568552] [D fake: 0.236650]\n",
      "[Epoch 16/50] [Batch 699/938] [D loss: 0.765370] [G loss: 1.308030] [D real: 0.698947] [D fake: 0.285013]\n",
      "[Epoch 16/50] [Batch 799/938] [D loss: 0.941253] [G loss: 1.160241] [D real: 0.625578] [D fake: 0.263271]\n",
      "[Epoch 16/50] [Batch 899/938] [D loss: 0.877234] [G loss: 1.081096] [D real: 0.715973] [D fake: 0.345210]\n",
      "[Epoch 17/50] [Batch 99/938] [D loss: 0.974225] [G loss: 1.203598] [D real: 0.646267] [D fake: 0.319072]\n",
      "[Epoch 17/50] [Batch 199/938] [D loss: 0.923582] [G loss: 1.213430] [D real: 0.665491] [D fake: 0.305863]\n",
      "[Epoch 17/50] [Batch 299/938] [D loss: 0.968713] [G loss: 1.867200] [D real: 0.780899] [D fake: 0.480090]\n",
      "[Epoch 17/50] [Batch 399/938] [D loss: 1.155484] [G loss: 1.691572] [D real: 0.736483] [D fake: 0.506322]\n",
      "[Epoch 17/50] [Batch 499/938] [D loss: 0.883339] [G loss: 1.136053] [D real: 0.691708] [D fake: 0.328035]\n",
      "[Epoch 17/50] [Batch 599/938] [D loss: 0.910213] [G loss: 1.479007] [D real: 0.700453] [D fake: 0.346607]\n",
      "[Epoch 17/50] [Batch 699/938] [D loss: 0.870006] [G loss: 1.185172] [D real: 0.675966] [D fake: 0.303576]\n",
      "[Epoch 17/50] [Batch 799/938] [D loss: 0.969380] [G loss: 0.956552] [D real: 0.659039] [D fake: 0.357646]\n",
      "[Epoch 17/50] [Batch 899/938] [D loss: 0.980766] [G loss: 1.427663] [D real: 0.678993] [D fake: 0.361609]\n",
      "[Epoch 18/50] [Batch 99/938] [D loss: 0.960523] [G loss: 1.258753] [D real: 0.656427] [D fake: 0.346964]\n",
      "[Epoch 18/50] [Batch 199/938] [D loss: 1.039371] [G loss: 1.415376] [D real: 0.784861] [D fake: 0.489500]\n",
      "[Epoch 18/50] [Batch 299/938] [D loss: 0.897596] [G loss: 1.358209] [D real: 0.644829] [D fake: 0.278183]\n",
      "[Epoch 18/50] [Batch 399/938] [D loss: 0.795288] [G loss: 1.278627] [D real: 0.722580] [D fake: 0.303003]\n",
      "[Epoch 18/50] [Batch 499/938] [D loss: 0.876111] [G loss: 1.218235] [D real: 0.665964] [D fake: 0.286855]\n",
      "[Epoch 18/50] [Batch 599/938] [D loss: 0.858372] [G loss: 1.220747] [D real: 0.696458] [D fake: 0.314409]\n",
      "[Epoch 18/50] [Batch 699/938] [D loss: 0.912271] [G loss: 1.136139] [D real: 0.622830] [D fake: 0.268274]\n",
      "[Epoch 18/50] [Batch 799/938] [D loss: 1.493831] [G loss: 2.784894] [D real: 0.904422] [D fake: 0.708223]\n",
      "[Epoch 18/50] [Batch 899/938] [D loss: 0.910554] [G loss: 1.276992] [D real: 0.713661] [D fake: 0.371944]\n",
      "[Epoch 19/50] [Batch 99/938] [D loss: 0.929727] [G loss: 1.347836] [D real: 0.599791] [D fake: 0.222406]\n",
      "[Epoch 19/50] [Batch 199/938] [D loss: 1.080366] [G loss: 1.511467] [D real: 0.679969] [D fake: 0.443486]\n",
      "[Epoch 19/50] [Batch 299/938] [D loss: 1.143679] [G loss: 0.835583] [D real: 0.488917] [D fake: 0.164850]\n",
      "[Epoch 19/50] [Batch 399/938] [D loss: 0.839616] [G loss: 1.414886] [D real: 0.758448] [D fake: 0.370999]\n",
      "[Epoch 19/50] [Batch 499/938] [D loss: 0.966468] [G loss: 1.653864] [D real: 0.676737] [D fake: 0.328066]\n",
      "[Epoch 19/50] [Batch 599/938] [D loss: 1.064726] [G loss: 1.638386] [D real: 0.672078] [D fake: 0.384302]\n",
      "[Epoch 19/50] [Batch 699/938] [D loss: 1.037698] [G loss: 1.614700] [D real: 0.702385] [D fake: 0.426841]\n",
      "[Epoch 19/50] [Batch 799/938] [D loss: 0.886661] [G loss: 1.663454] [D real: 0.806654] [D fake: 0.447255]\n",
      "[Epoch 19/50] [Batch 899/938] [D loss: 0.854767] [G loss: 1.443842] [D real: 0.739622] [D fake: 0.361020]\n",
      "[Epoch 20/50] [Batch 99/938] [D loss: 0.959240] [G loss: 0.980159] [D real: 0.587331] [D fake: 0.205030]\n",
      "[Epoch 20/50] [Batch 199/938] [D loss: 0.961259] [G loss: 1.221946] [D real: 0.631229] [D fake: 0.313145]\n",
      "[Epoch 20/50] [Batch 299/938] [D loss: 0.816444] [G loss: 1.674994] [D real: 0.754187] [D fake: 0.360108]\n",
      "[Epoch 20/50] [Batch 399/938] [D loss: 0.950020] [G loss: 2.326936] [D real: 0.788620] [D fake: 0.451261]\n",
      "[Epoch 20/50] [Batch 499/938] [D loss: 1.013510] [G loss: 1.892145] [D real: 0.710109] [D fake: 0.422931]\n",
      "[Epoch 20/50] [Batch 599/938] [D loss: 0.977474] [G loss: 1.331889] [D real: 0.653978] [D fake: 0.318014]\n",
      "[Epoch 20/50] [Batch 699/938] [D loss: 0.925753] [G loss: 1.773499] [D real: 0.627128] [D fake: 0.249431]\n",
      "[Epoch 20/50] [Batch 799/938] [D loss: 1.039566] [G loss: 0.849939] [D real: 0.526561] [D fake: 0.231980]\n",
      "[Epoch 20/50] [Batch 899/938] [D loss: 0.853480] [G loss: 1.241132] [D real: 0.712851] [D fake: 0.340581]\n",
      "[Epoch 21/50] [Batch 99/938] [D loss: 0.973880] [G loss: 0.817273] [D real: 0.588972] [D fake: 0.249300]\n",
      "[Epoch 21/50] [Batch 199/938] [D loss: 0.810053] [G loss: 1.182639] [D real: 0.694785] [D fake: 0.263884]\n",
      "[Epoch 21/50] [Batch 299/938] [D loss: 1.048666] [G loss: 1.912133] [D real: 0.806209] [D fake: 0.519568]\n",
      "[Epoch 21/50] [Batch 399/938] [D loss: 1.081919] [G loss: 1.693523] [D real: 0.821672] [D fake: 0.495961]\n",
      "[Epoch 21/50] [Batch 499/938] [D loss: 0.962957] [G loss: 1.713845] [D real: 0.620349] [D fake: 0.296285]\n",
      "[Epoch 21/50] [Batch 599/938] [D loss: 0.885192] [G loss: 1.534477] [D real: 0.752487] [D fake: 0.389259]\n",
      "[Epoch 21/50] [Batch 699/938] [D loss: 1.196476] [G loss: 1.863182] [D real: 0.793911] [D fake: 0.547685]\n",
      "[Epoch 21/50] [Batch 799/938] [D loss: 1.134178] [G loss: 1.686500] [D real: 0.797732] [D fake: 0.536531]\n",
      "[Epoch 21/50] [Batch 899/938] [D loss: 1.054236] [G loss: 1.334673] [D real: 0.564795] [D fake: 0.232593]\n",
      "[Epoch 22/50] [Batch 99/938] [D loss: 0.992153] [G loss: 1.931327] [D real: 0.820610] [D fake: 0.497940]\n",
      "[Epoch 22/50] [Batch 199/938] [D loss: 0.847796] [G loss: 1.460559] [D real: 0.681871] [D fake: 0.294539]\n",
      "[Epoch 22/50] [Batch 299/938] [D loss: 1.050107] [G loss: 2.015761] [D real: 0.807334] [D fake: 0.507805]\n",
      "[Epoch 22/50] [Batch 399/938] [D loss: 0.931647] [G loss: 1.244122] [D real: 0.661307] [D fake: 0.329777]\n",
      "[Epoch 22/50] [Batch 499/938] [D loss: 1.201357] [G loss: 0.577299] [D real: 0.452468] [D fake: 0.187171]\n",
      "[Epoch 22/50] [Batch 599/938] [D loss: 0.828433] [G loss: 1.717833] [D real: 0.766651] [D fake: 0.375476]\n",
      "[Epoch 22/50] [Batch 699/938] [D loss: 0.861739] [G loss: 1.291246] [D real: 0.705402] [D fake: 0.329563]\n",
      "[Epoch 22/50] [Batch 799/938] [D loss: 0.940421] [G loss: 1.574257] [D real: 0.757573] [D fake: 0.386013]\n",
      "[Epoch 22/50] [Batch 899/938] [D loss: 0.911192] [G loss: 1.326631] [D real: 0.647268] [D fake: 0.286493]\n",
      "[Epoch 23/50] [Batch 99/938] [D loss: 0.946000] [G loss: 1.535027] [D real: 0.631999] [D fake: 0.281324]\n",
      "[Epoch 23/50] [Batch 199/938] [D loss: 0.898911] [G loss: 1.161804] [D real: 0.628423] [D fake: 0.272493]\n",
      "[Epoch 23/50] [Batch 299/938] [D loss: 0.915133] [G loss: 0.741860] [D real: 0.565687] [D fake: 0.180233]\n",
      "[Epoch 23/50] [Batch 399/938] [D loss: 0.918292] [G loss: 1.167086] [D real: 0.667412] [D fake: 0.325869]\n",
      "[Epoch 23/50] [Batch 499/938] [D loss: 1.049854] [G loss: 1.832687] [D real: 0.712394] [D fake: 0.435340]\n",
      "[Epoch 23/50] [Batch 599/938] [D loss: 0.948401] [G loss: 1.478717] [D real: 0.645003] [D fake: 0.297718]\n",
      "[Epoch 23/50] [Batch 699/938] [D loss: 1.062361] [G loss: 1.065989] [D real: 0.554256] [D fake: 0.229632]\n",
      "[Epoch 23/50] [Batch 799/938] [D loss: 0.840504] [G loss: 1.903188] [D real: 0.808488] [D fake: 0.395818]\n",
      "[Epoch 23/50] [Batch 899/938] [D loss: 1.081243] [G loss: 1.218334] [D real: 0.551666] [D fake: 0.283088]\n",
      "[Epoch 24/50] [Batch 99/938] [D loss: 0.911438] [G loss: 1.566653] [D real: 0.755996] [D fake: 0.402843]\n",
      "[Epoch 24/50] [Batch 199/938] [D loss: 0.982566] [G loss: 1.666878] [D real: 0.767165] [D fake: 0.450281]\n",
      "[Epoch 24/50] [Batch 299/938] [D loss: 0.971804] [G loss: 1.721680] [D real: 0.662505] [D fake: 0.325923]\n",
      "[Epoch 24/50] [Batch 399/938] [D loss: 1.284082] [G loss: 0.612124] [D real: 0.424318] [D fake: 0.172833]\n",
      "[Epoch 24/50] [Batch 499/938] [D loss: 0.860143] [G loss: 1.433513] [D real: 0.703041] [D fake: 0.288727]\n",
      "[Epoch 24/50] [Batch 599/938] [D loss: 0.904673] [G loss: 1.404255] [D real: 0.737167] [D fake: 0.374544]\n",
      "[Epoch 24/50] [Batch 699/938] [D loss: 0.970858] [G loss: 0.919923] [D real: 0.594915] [D fake: 0.245714]\n",
      "[Epoch 24/50] [Batch 799/938] [D loss: 1.015863] [G loss: 1.199005] [D real: 0.695754] [D fake: 0.392261]\n",
      "[Epoch 24/50] [Batch 899/938] [D loss: 0.942898] [G loss: 1.705051] [D real: 0.734636] [D fake: 0.424677]\n",
      "[Epoch 25/50] [Batch 99/938] [D loss: 1.130687] [G loss: 1.410580] [D real: 0.741910] [D fake: 0.479712]\n",
      "[Epoch 25/50] [Batch 199/938] [D loss: 1.008806] [G loss: 1.609921] [D real: 0.674835] [D fake: 0.355431]\n",
      "[Epoch 25/50] [Batch 299/938] [D loss: 0.940680] [G loss: 1.861640] [D real: 0.699960] [D fake: 0.360684]\n",
      "[Epoch 25/50] [Batch 399/938] [D loss: 0.969670] [G loss: 1.005853] [D real: 0.644663] [D fake: 0.289189]\n",
      "[Epoch 25/50] [Batch 499/938] [D loss: 0.846907] [G loss: 1.910056] [D real: 0.750310] [D fake: 0.362350]\n",
      "[Epoch 25/50] [Batch 599/938] [D loss: 1.033446] [G loss: 0.998501] [D real: 0.595993] [D fake: 0.290629]\n",
      "[Epoch 25/50] [Batch 699/938] [D loss: 1.064377] [G loss: 1.088519] [D real: 0.626653] [D fake: 0.349792]\n",
      "[Epoch 25/50] [Batch 799/938] [D loss: 0.962219] [G loss: 1.631021] [D real: 0.703651] [D fake: 0.383489]\n",
      "[Epoch 25/50] [Batch 899/938] [D loss: 1.020462] [G loss: 1.315607] [D real: 0.746257] [D fake: 0.434586]\n",
      "[Epoch 26/50] [Batch 99/938] [D loss: 0.965833] [G loss: 1.269770] [D real: 0.689397] [D fake: 0.366537]\n",
      "[Epoch 26/50] [Batch 199/938] [D loss: 0.905146] [G loss: 1.075284] [D real: 0.604218] [D fake: 0.248616]\n",
      "[Epoch 26/50] [Batch 299/938] [D loss: 0.985438] [G loss: 1.220121] [D real: 0.721357] [D fake: 0.392314]\n",
      "[Epoch 26/50] [Batch 399/938] [D loss: 0.866449] [G loss: 0.994821] [D real: 0.671748] [D fake: 0.314915]\n",
      "[Epoch 26/50] [Batch 499/938] [D loss: 0.984355] [G loss: 1.360616] [D real: 0.782893] [D fake: 0.458710]\n",
      "[Epoch 26/50] [Batch 599/938] [D loss: 0.954180] [G loss: 1.366277] [D real: 0.652991] [D fake: 0.294329]\n",
      "[Epoch 26/50] [Batch 699/938] [D loss: 0.966554] [G loss: 1.127918] [D real: 0.593553] [D fake: 0.268878]\n",
      "[Epoch 26/50] [Batch 799/938] [D loss: 0.978707] [G loss: 1.220996] [D real: 0.631124] [D fake: 0.290307]\n",
      "[Epoch 26/50] [Batch 899/938] [D loss: 0.888739] [G loss: 1.702230] [D real: 0.732066] [D fake: 0.378728]\n",
      "[Epoch 27/50] [Batch 99/938] [D loss: 1.112454] [G loss: 1.791533] [D real: 0.828591] [D fake: 0.527178]\n",
      "[Epoch 27/50] [Batch 199/938] [D loss: 1.072414] [G loss: 0.810654] [D real: 0.591675] [D fake: 0.324443]\n",
      "[Epoch 27/50] [Batch 299/938] [D loss: 0.885934] [G loss: 1.878260] [D real: 0.756157] [D fake: 0.383153]\n",
      "[Epoch 27/50] [Batch 399/938] [D loss: 1.029132] [G loss: 0.983731] [D real: 0.577289] [D fake: 0.240722]\n",
      "[Epoch 27/50] [Batch 499/938] [D loss: 0.934246] [G loss: 1.403716] [D real: 0.725203] [D fake: 0.396003]\n",
      "[Epoch 27/50] [Batch 599/938] [D loss: 0.965313] [G loss: 1.169658] [D real: 0.613320] [D fake: 0.239696]\n",
      "[Epoch 27/50] [Batch 699/938] [D loss: 0.862352] [G loss: 1.322756] [D real: 0.723689] [D fake: 0.347616]\n",
      "[Epoch 27/50] [Batch 799/938] [D loss: 0.991066] [G loss: 1.498748] [D real: 0.714679] [D fake: 0.377389]\n",
      "[Epoch 27/50] [Batch 899/938] [D loss: 0.829933] [G loss: 1.579127] [D real: 0.773608] [D fake: 0.382615]\n",
      "[Epoch 28/50] [Batch 99/938] [D loss: 0.859965] [G loss: 1.667212] [D real: 0.790778] [D fake: 0.403074]\n",
      "[Epoch 28/50] [Batch 199/938] [D loss: 1.071495] [G loss: 1.745615] [D real: 0.735578] [D fake: 0.453932]\n",
      "[Epoch 28/50] [Batch 299/938] [D loss: 0.841644] [G loss: 1.392335] [D real: 0.703132] [D fake: 0.330187]\n",
      "[Epoch 28/50] [Batch 399/938] [D loss: 1.092287] [G loss: 1.990409] [D real: 0.833920] [D fake: 0.528597]\n",
      "[Epoch 28/50] [Batch 499/938] [D loss: 0.948588] [G loss: 1.425857] [D real: 0.690949] [D fake: 0.335054]\n",
      "[Epoch 28/50] [Batch 599/938] [D loss: 1.013757] [G loss: 0.932720] [D real: 0.568371] [D fake: 0.208227]\n",
      "[Epoch 28/50] [Batch 699/938] [D loss: 0.932948] [G loss: 1.349869] [D real: 0.572419] [D fake: 0.169447]\n",
      "[Epoch 28/50] [Batch 799/938] [D loss: 0.876730] [G loss: 1.499424] [D real: 0.719319] [D fake: 0.351756]\n",
      "[Epoch 28/50] [Batch 899/938] [D loss: 0.772082] [G loss: 0.945683] [D real: 0.686592] [D fake: 0.220315]\n",
      "[Epoch 29/50] [Batch 99/938] [D loss: 1.013237] [G loss: 1.370319] [D real: 0.688281] [D fake: 0.398897]\n",
      "[Epoch 29/50] [Batch 199/938] [D loss: 0.906115] [G loss: 1.289997] [D real: 0.619485] [D fake: 0.254552]\n",
      "[Epoch 29/50] [Batch 299/938] [D loss: 0.958719] [G loss: 1.280617] [D real: 0.642316] [D fake: 0.273334]\n",
      "[Epoch 29/50] [Batch 399/938] [D loss: 0.823631] [G loss: 1.494699] [D real: 0.746058] [D fake: 0.344882]\n",
      "[Epoch 29/50] [Batch 499/938] [D loss: 0.752522] [G loss: 2.067154] [D real: 0.738149] [D fake: 0.291166]\n",
      "[Epoch 29/50] [Batch 599/938] [D loss: 1.031925] [G loss: 1.177278] [D real: 0.568146] [D fake: 0.188349]\n",
      "[Epoch 29/50] [Batch 699/938] [D loss: 0.949153] [G loss: 1.320686] [D real: 0.635241] [D fake: 0.264973]\n",
      "[Epoch 29/50] [Batch 799/938] [D loss: 0.876501] [G loss: 1.867053] [D real: 0.833131] [D fake: 0.446754]\n",
      "[Epoch 29/50] [Batch 899/938] [D loss: 1.023058] [G loss: 1.754759] [D real: 0.734497] [D fake: 0.431159]\n",
      "[Epoch 30/50] [Batch 99/938] [D loss: 0.875856] [G loss: 1.004973] [D real: 0.584201] [D fake: 0.148126]\n",
      "[Epoch 30/50] [Batch 199/938] [D loss: 0.995764] [G loss: 1.976676] [D real: 0.739480] [D fake: 0.411998]\n",
      "[Epoch 30/50] [Batch 299/938] [D loss: 0.907387] [G loss: 1.543285] [D real: 0.726086] [D fake: 0.383667]\n",
      "[Epoch 30/50] [Batch 399/938] [D loss: 0.889144] [G loss: 1.189141] [D real: 0.627993] [D fake: 0.259996]\n",
      "[Epoch 30/50] [Batch 499/938] [D loss: 1.033283] [G loss: 1.419605] [D real: 0.641544] [D fake: 0.350630]\n",
      "[Epoch 30/50] [Batch 599/938] [D loss: 0.921659] [G loss: 1.726207] [D real: 0.719180] [D fake: 0.365733]\n",
      "[Epoch 30/50] [Batch 699/938] [D loss: 0.906953] [G loss: 1.092805] [D real: 0.679250] [D fake: 0.332843]\n",
      "[Epoch 30/50] [Batch 799/938] [D loss: 0.924309] [G loss: 1.254940] [D real: 0.618988] [D fake: 0.256566]\n",
      "[Epoch 30/50] [Batch 899/938] [D loss: 1.005808] [G loss: 1.142478] [D real: 0.660109] [D fake: 0.345729]\n",
      "[Epoch 31/50] [Batch 99/938] [D loss: 0.897850] [G loss: 2.051387] [D real: 0.751238] [D fake: 0.371798]\n",
      "[Epoch 31/50] [Batch 199/938] [D loss: 0.950923] [G loss: 1.906200] [D real: 0.812689] [D fake: 0.462602]\n",
      "[Epoch 31/50] [Batch 299/938] [D loss: 0.951439] [G loss: 1.016941] [D real: 0.595967] [D fake: 0.244292]\n",
      "[Epoch 31/50] [Batch 399/938] [D loss: 1.002181] [G loss: 1.197490] [D real: 0.618589] [D fake: 0.314634]\n",
      "[Epoch 31/50] [Batch 499/938] [D loss: 0.837078] [G loss: 1.101729] [D real: 0.712997] [D fake: 0.307279]\n",
      "[Epoch 31/50] [Batch 599/938] [D loss: 1.086107] [G loss: 2.218787] [D real: 0.824591] [D fake: 0.533872]\n",
      "[Epoch 31/50] [Batch 699/938] [D loss: 0.951535] [G loss: 1.535957] [D real: 0.722360] [D fake: 0.388619]\n",
      "[Epoch 31/50] [Batch 799/938] [D loss: 0.919398] [G loss: 1.955961] [D real: 0.791603] [D fake: 0.427662]\n",
      "[Epoch 31/50] [Batch 899/938] [D loss: 1.051530] [G loss: 0.915498] [D real: 0.554484] [D fake: 0.206235]\n",
      "[Epoch 32/50] [Batch 99/938] [D loss: 0.907259] [G loss: 1.095844] [D real: 0.610949] [D fake: 0.215574]\n",
      "[Epoch 32/50] [Batch 199/938] [D loss: 0.914766] [G loss: 1.354022] [D real: 0.756346] [D fake: 0.395896]\n",
      "[Epoch 32/50] [Batch 299/938] [D loss: 0.875079] [G loss: 1.421122] [D real: 0.760920] [D fake: 0.389325]\n",
      "[Epoch 32/50] [Batch 399/938] [D loss: 1.028709] [G loss: 1.593329] [D real: 0.758788] [D fake: 0.454210]\n",
      "[Epoch 32/50] [Batch 499/938] [D loss: 0.807638] [G loss: 1.808095] [D real: 0.793046] [D fake: 0.368157]\n",
      "[Epoch 32/50] [Batch 599/938] [D loss: 0.904055] [G loss: 1.424425] [D real: 0.647745] [D fake: 0.276808]\n",
      "[Epoch 32/50] [Batch 699/938] [D loss: 0.940227] [G loss: 1.143422] [D real: 0.647669] [D fake: 0.275684]\n",
      "[Epoch 32/50] [Batch 799/938] [D loss: 0.874880] [G loss: 1.171494] [D real: 0.658732] [D fake: 0.238982]\n",
      "[Epoch 32/50] [Batch 899/938] [D loss: 0.910375] [G loss: 1.115497] [D real: 0.652456] [D fake: 0.297442]\n",
      "[Epoch 33/50] [Batch 99/938] [D loss: 0.928440] [G loss: 1.323653] [D real: 0.614272] [D fake: 0.222318]\n",
      "[Epoch 33/50] [Batch 199/938] [D loss: 1.153860] [G loss: 1.502214] [D real: 0.681748] [D fake: 0.461527]\n",
      "[Epoch 33/50] [Batch 299/938] [D loss: 0.774568] [G loss: 1.428970] [D real: 0.772810] [D fake: 0.308259]\n",
      "[Epoch 33/50] [Batch 399/938] [D loss: 0.968296] [G loss: 1.692433] [D real: 0.736703] [D fake: 0.416155]\n",
      "[Epoch 33/50] [Batch 499/938] [D loss: 1.063310] [G loss: 1.172377] [D real: 0.594439] [D fake: 0.269835]\n",
      "[Epoch 33/50] [Batch 599/938] [D loss: 0.913817] [G loss: 1.350744] [D real: 0.733221] [D fake: 0.376534]\n",
      "[Epoch 33/50] [Batch 699/938] [D loss: 0.874926] [G loss: 2.112842] [D real: 0.759871] [D fake: 0.392594]\n",
      "[Epoch 33/50] [Batch 799/938] [D loss: 0.809834] [G loss: 0.994302] [D real: 0.632445] [D fake: 0.186386]\n",
      "[Epoch 33/50] [Batch 899/938] [D loss: 0.873194] [G loss: 1.583763] [D real: 0.767504] [D fake: 0.364047]\n",
      "[Epoch 34/50] [Batch 99/938] [D loss: 0.699621] [G loss: 1.645733] [D real: 0.743836] [D fake: 0.260572]\n",
      "[Epoch 34/50] [Batch 199/938] [D loss: 1.338861] [G loss: 1.818344] [D real: 0.812859] [D fake: 0.599272]\n",
      "[Epoch 34/50] [Batch 299/938] [D loss: 1.029796] [G loss: 1.421579] [D real: 0.588426] [D fake: 0.250116]\n",
      "[Epoch 34/50] [Batch 399/938] [D loss: 1.033677] [G loss: 1.913685] [D real: 0.753820] [D fake: 0.437400]\n",
      "[Epoch 34/50] [Batch 499/938] [D loss: 0.974921] [G loss: 1.509965] [D real: 0.716326] [D fake: 0.374932]\n",
      "[Epoch 34/50] [Batch 599/938] [D loss: 0.774866] [G loss: 1.336553] [D real: 0.642906] [D fake: 0.186592]\n",
      "[Epoch 34/50] [Batch 699/938] [D loss: 0.971998] [G loss: 1.132418] [D real: 0.609259] [D fake: 0.237668]\n",
      "[Epoch 34/50] [Batch 799/938] [D loss: 0.869269] [G loss: 1.181747] [D real: 0.638695] [D fake: 0.253215]\n",
      "[Epoch 34/50] [Batch 899/938] [D loss: 0.973586] [G loss: 1.173376] [D real: 0.717419] [D fake: 0.386784]\n",
      "[Epoch 35/50] [Batch 99/938] [D loss: 0.942267] [G loss: 1.252280] [D real: 0.588833] [D fake: 0.161925]\n",
      "[Epoch 35/50] [Batch 199/938] [D loss: 0.942342] [G loss: 0.948481] [D real: 0.589400] [D fake: 0.205511]\n",
      "[Epoch 35/50] [Batch 299/938] [D loss: 0.900995] [G loss: 1.231711] [D real: 0.612139] [D fake: 0.185067]\n",
      "[Epoch 35/50] [Batch 399/938] [D loss: 0.965953] [G loss: 1.273562] [D real: 0.674357] [D fake: 0.342630]\n",
      "[Epoch 35/50] [Batch 499/938] [D loss: 0.805568] [G loss: 1.503933] [D real: 0.683207] [D fake: 0.242872]\n",
      "[Epoch 35/50] [Batch 599/938] [D loss: 0.891280] [G loss: 1.952972] [D real: 0.781624] [D fake: 0.405736]\n",
      "[Epoch 35/50] [Batch 699/938] [D loss: 1.195410] [G loss: 1.949350] [D real: 0.786948] [D fake: 0.511030]\n",
      "[Epoch 35/50] [Batch 799/938] [D loss: 1.024083] [G loss: 0.919000] [D real: 0.566803] [D fake: 0.219715]\n",
      "[Epoch 35/50] [Batch 899/938] [D loss: 0.883971] [G loss: 1.477735] [D real: 0.708831] [D fake: 0.338033]\n",
      "[Epoch 36/50] [Batch 99/938] [D loss: 0.935613] [G loss: 1.370978] [D real: 0.620363] [D fake: 0.264575]\n",
      "[Epoch 36/50] [Batch 199/938] [D loss: 0.990711] [G loss: 1.704096] [D real: 0.685884] [D fake: 0.385317]\n",
      "[Epoch 36/50] [Batch 299/938] [D loss: 0.941509] [G loss: 1.830112] [D real: 0.786499] [D fake: 0.426475]\n",
      "[Epoch 36/50] [Batch 399/938] [D loss: 0.980577] [G loss: 1.157364] [D real: 0.668704] [D fake: 0.340050]\n",
      "[Epoch 36/50] [Batch 499/938] [D loss: 0.883586] [G loss: 1.249614] [D real: 0.604141] [D fake: 0.176279]\n",
      "[Epoch 36/50] [Batch 599/938] [D loss: 0.990807] [G loss: 1.036018] [D real: 0.568041] [D fake: 0.183046]\n",
      "[Epoch 36/50] [Batch 699/938] [D loss: 1.294456] [G loss: 2.282353] [D real: 0.877617] [D fake: 0.603490]\n",
      "[Epoch 36/50] [Batch 799/938] [D loss: 0.919196] [G loss: 1.562046] [D real: 0.734225] [D fake: 0.390815]\n",
      "[Epoch 36/50] [Batch 899/938] [D loss: 1.015001] [G loss: 0.914295] [D real: 0.556369] [D fake: 0.177510]\n",
      "[Epoch 37/50] [Batch 99/938] [D loss: 0.821521] [G loss: 1.610015] [D real: 0.671248] [D fake: 0.238892]\n",
      "[Epoch 37/50] [Batch 199/938] [D loss: 0.953436] [G loss: 1.163038] [D real: 0.605694] [D fake: 0.236197]\n",
      "[Epoch 37/50] [Batch 299/938] [D loss: 0.864537] [G loss: 1.074976] [D real: 0.650312] [D fake: 0.264358]\n",
      "[Epoch 37/50] [Batch 399/938] [D loss: 0.833314] [G loss: 1.765982] [D real: 0.724763] [D fake: 0.303375]\n",
      "[Epoch 37/50] [Batch 499/938] [D loss: 0.832433] [G loss: 1.862601] [D real: 0.798347] [D fake: 0.382911]\n",
      "[Epoch 37/50] [Batch 599/938] [D loss: 1.003758] [G loss: 1.031400] [D real: 0.663972] [D fake: 0.346826]\n",
      "[Epoch 37/50] [Batch 699/938] [D loss: 0.803934] [G loss: 1.316652] [D real: 0.684375] [D fake: 0.268993]\n",
      "[Epoch 37/50] [Batch 799/938] [D loss: 0.957413] [G loss: 1.362272] [D real: 0.629804] [D fake: 0.295374]\n",
      "[Epoch 37/50] [Batch 899/938] [D loss: 0.872048] [G loss: 1.142208] [D real: 0.719935] [D fake: 0.345193]\n",
      "[Epoch 38/50] [Batch 99/938] [D loss: 1.047962] [G loss: 0.981325] [D real: 0.554569] [D fake: 0.201141]\n",
      "[Epoch 38/50] [Batch 199/938] [D loss: 0.821273] [G loss: 1.357090] [D real: 0.681228] [D fake: 0.233851]\n",
      "[Epoch 38/50] [Batch 299/938] [D loss: 1.115865] [G loss: 0.829568] [D real: 0.545079] [D fake: 0.245516]\n",
      "[Epoch 38/50] [Batch 399/938] [D loss: 0.820672] [G loss: 1.278360] [D real: 0.610044] [D fake: 0.167777]\n",
      "[Epoch 38/50] [Batch 499/938] [D loss: 0.858475] [G loss: 1.604214] [D real: 0.727480] [D fake: 0.350512]\n",
      "[Epoch 38/50] [Batch 599/938] [D loss: 0.822423] [G loss: 1.500954] [D real: 0.760825] [D fake: 0.356043]\n",
      "[Epoch 38/50] [Batch 699/938] [D loss: 0.868028] [G loss: 1.819869] [D real: 0.728316] [D fake: 0.335984]\n",
      "[Epoch 38/50] [Batch 799/938] [D loss: 0.944134] [G loss: 1.983799] [D real: 0.836349] [D fake: 0.459132]\n",
      "[Epoch 38/50] [Batch 899/938] [D loss: 0.772243] [G loss: 1.750604] [D real: 0.768154] [D fake: 0.336792]\n",
      "[Epoch 39/50] [Batch 99/938] [D loss: 0.871429] [G loss: 1.366293] [D real: 0.718458] [D fake: 0.346141]\n",
      "[Epoch 39/50] [Batch 199/938] [D loss: 1.032547] [G loss: 1.323678] [D real: 0.650651] [D fake: 0.340511]\n",
      "[Epoch 39/50] [Batch 299/938] [D loss: 0.913883] [G loss: 1.836977] [D real: 0.750420] [D fake: 0.377271]\n",
      "[Epoch 39/50] [Batch 399/938] [D loss: 0.937742] [G loss: 1.473788] [D real: 0.574755] [D fake: 0.180157]\n",
      "[Epoch 39/50] [Batch 499/938] [D loss: 0.915335] [G loss: 1.535816] [D real: 0.734506] [D fake: 0.368112]\n",
      "[Epoch 39/50] [Batch 599/938] [D loss: 0.944686] [G loss: 1.450701] [D real: 0.668770] [D fake: 0.305515]\n",
      "[Epoch 39/50] [Batch 699/938] [D loss: 1.000861] [G loss: 1.100988] [D real: 0.627273] [D fake: 0.275326]\n",
      "[Epoch 39/50] [Batch 799/938] [D loss: 0.961796] [G loss: 1.094068] [D real: 0.569388] [D fake: 0.156192]\n",
      "[Epoch 39/50] [Batch 899/938] [D loss: 0.749216] [G loss: 1.456431] [D real: 0.650617] [D fake: 0.189095]\n",
      "[Epoch 40/50] [Batch 99/938] [D loss: 0.837490] [G loss: 1.466661] [D real: 0.679021] [D fake: 0.246266]\n",
      "[Epoch 40/50] [Batch 199/938] [D loss: 0.932757] [G loss: 1.706644] [D real: 0.721353] [D fake: 0.367994]\n",
      "[Epoch 40/50] [Batch 299/938] [D loss: 0.969704] [G loss: 1.513737] [D real: 0.720550] [D fake: 0.375552]\n",
      "[Epoch 40/50] [Batch 399/938] [D loss: 0.919907] [G loss: 1.331001] [D real: 0.645974] [D fake: 0.261448]\n",
      "[Epoch 40/50] [Batch 499/938] [D loss: 0.995910] [G loss: 0.942974] [D real: 0.554255] [D fake: 0.211095]\n",
      "[Epoch 40/50] [Batch 599/938] [D loss: 0.845702] [G loss: 1.056937] [D real: 0.681956] [D fake: 0.290414]\n",
      "[Epoch 40/50] [Batch 699/938] [D loss: 0.999439] [G loss: 2.095626] [D real: 0.805107] [D fake: 0.465059]\n",
      "[Epoch 40/50] [Batch 799/938] [D loss: 0.904398] [G loss: 2.397926] [D real: 0.838584] [D fake: 0.438015]\n",
      "[Epoch 40/50] [Batch 899/938] [D loss: 0.996326] [G loss: 0.852923] [D real: 0.631546] [D fake: 0.262531]\n",
      "[Epoch 41/50] [Batch 99/938] [D loss: 0.896725] [G loss: 1.799094] [D real: 0.747558] [D fake: 0.339468]\n",
      "[Epoch 41/50] [Batch 199/938] [D loss: 0.963874] [G loss: 1.356822] [D real: 0.743392] [D fake: 0.398625]\n",
      "[Epoch 41/50] [Batch 299/938] [D loss: 1.009205] [G loss: 1.103437] [D real: 0.615605] [D fake: 0.287579]\n",
      "[Epoch 41/50] [Batch 399/938] [D loss: 0.849865] [G loss: 1.951272] [D real: 0.731431] [D fake: 0.300172]\n",
      "[Epoch 41/50] [Batch 499/938] [D loss: 0.920232] [G loss: 1.475362] [D real: 0.731283] [D fake: 0.344341]\n",
      "[Epoch 41/50] [Batch 599/938] [D loss: 1.020537] [G loss: 1.756619] [D real: 0.699356] [D fake: 0.333371]\n",
      "[Epoch 41/50] [Batch 699/938] [D loss: 1.048458] [G loss: 0.854074] [D real: 0.579373] [D fake: 0.250671]\n",
      "[Epoch 41/50] [Batch 799/938] [D loss: 0.958432] [G loss: 1.343840] [D real: 0.672119] [D fake: 0.328510]\n",
      "[Epoch 41/50] [Batch 899/938] [D loss: 1.039972] [G loss: 1.017475] [D real: 0.564845] [D fake: 0.236196]\n",
      "[Epoch 42/50] [Batch 99/938] [D loss: 0.944942] [G loss: 1.083906] [D real: 0.683100] [D fake: 0.321754]\n",
      "[Epoch 42/50] [Batch 199/938] [D loss: 0.927194] [G loss: 1.541286] [D real: 0.761922] [D fake: 0.397949]\n",
      "[Epoch 42/50] [Batch 299/938] [D loss: 0.876365] [G loss: 2.211161] [D real: 0.821562] [D fake: 0.426999]\n",
      "[Epoch 42/50] [Batch 399/938] [D loss: 0.863812] [G loss: 1.444752] [D real: 0.674309] [D fake: 0.276979]\n",
      "[Epoch 42/50] [Batch 499/938] [D loss: 1.068343] [G loss: 1.449729] [D real: 0.588223] [D fake: 0.248221]\n",
      "[Epoch 42/50] [Batch 599/938] [D loss: 0.853082] [G loss: 1.931163] [D real: 0.733533] [D fake: 0.310367]\n",
      "[Epoch 42/50] [Batch 699/938] [D loss: 0.964271] [G loss: 1.187886] [D real: 0.593947] [D fake: 0.219658]\n",
      "[Epoch 42/50] [Batch 799/938] [D loss: 1.017670] [G loss: 1.223159] [D real: 0.577506] [D fake: 0.255186]\n",
      "[Epoch 42/50] [Batch 899/938] [D loss: 0.943831] [G loss: 1.296140] [D real: 0.755925] [D fake: 0.408382]\n",
      "[Epoch 43/50] [Batch 99/938] [D loss: 0.931172] [G loss: 1.158264] [D real: 0.659930] [D fake: 0.304646]\n",
      "[Epoch 43/50] [Batch 199/938] [D loss: 1.090960] [G loss: 1.390059] [D real: 0.667674] [D fake: 0.394646]\n",
      "[Epoch 43/50] [Batch 299/938] [D loss: 1.114273] [G loss: 1.018858] [D real: 0.537700] [D fake: 0.222275]\n",
      "[Epoch 43/50] [Batch 399/938] [D loss: 0.853980] [G loss: 1.396726] [D real: 0.619972] [D fake: 0.152955]\n",
      "[Epoch 43/50] [Batch 499/938] [D loss: 0.854948] [G loss: 1.814651] [D real: 0.743241] [D fake: 0.321519]\n",
      "[Epoch 43/50] [Batch 599/938] [D loss: 1.061408] [G loss: 0.838385] [D real: 0.536755] [D fake: 0.171398]\n",
      "[Epoch 43/50] [Batch 699/938] [D loss: 0.906942] [G loss: 1.358469] [D real: 0.722107] [D fake: 0.355087]\n",
      "[Epoch 43/50] [Batch 799/938] [D loss: 0.889805] [G loss: 1.442886] [D real: 0.695533] [D fake: 0.331687]\n",
      "[Epoch 43/50] [Batch 899/938] [D loss: 1.001422] [G loss: 1.707314] [D real: 0.753340] [D fake: 0.402610]\n",
      "[Epoch 44/50] [Batch 99/938] [D loss: 0.886829] [G loss: 1.626851] [D real: 0.777121] [D fake: 0.400712]\n",
      "[Epoch 44/50] [Batch 199/938] [D loss: 0.853855] [G loss: 1.596219] [D real: 0.751171] [D fake: 0.330703]\n",
      "[Epoch 44/50] [Batch 299/938] [D loss: 0.860447] [G loss: 1.459471] [D real: 0.645445] [D fake: 0.230925]\n",
      "[Epoch 44/50] [Batch 399/938] [D loss: 0.862464] [G loss: 1.985732] [D real: 0.800553] [D fake: 0.393842]\n",
      "[Epoch 44/50] [Batch 499/938] [D loss: 0.871798] [G loss: 1.168703] [D real: 0.638357] [D fake: 0.218767]\n",
      "[Epoch 44/50] [Batch 599/938] [D loss: 1.075919] [G loss: 2.573410] [D real: 0.814264] [D fake: 0.450933]\n",
      "[Epoch 44/50] [Batch 699/938] [D loss: 1.143668] [G loss: 2.036975] [D real: 0.796281] [D fake: 0.489160]\n",
      "[Epoch 44/50] [Batch 799/938] [D loss: 0.952417] [G loss: 1.464282] [D real: 0.671590] [D fake: 0.287903]\n",
      "[Epoch 44/50] [Batch 899/938] [D loss: 0.900666] [G loss: 1.005526] [D real: 0.662851] [D fake: 0.267682]\n",
      "[Epoch 45/50] [Batch 99/938] [D loss: 0.955348] [G loss: 1.121429] [D real: 0.610198] [D fake: 0.202410]\n",
      "[Epoch 45/50] [Batch 199/938] [D loss: 0.892995] [G loss: 1.787337] [D real: 0.781109] [D fake: 0.419623]\n",
      "[Epoch 45/50] [Batch 299/938] [D loss: 1.100687] [G loss: 1.013652] [D real: 0.605580] [D fake: 0.270780]\n",
      "[Epoch 45/50] [Batch 399/938] [D loss: 0.730151] [G loss: 2.026091] [D real: 0.794883] [D fake: 0.326996]\n",
      "[Epoch 45/50] [Batch 499/938] [D loss: 1.006734] [G loss: 1.071572] [D real: 0.564198] [D fake: 0.181945]\n",
      "[Epoch 45/50] [Batch 599/938] [D loss: 1.017676] [G loss: 1.512587] [D real: 0.759960] [D fake: 0.431699]\n",
      "[Epoch 45/50] [Batch 699/938] [D loss: 0.782752] [G loss: 1.620840] [D real: 0.753618] [D fake: 0.311330]\n",
      "[Epoch 45/50] [Batch 799/938] [D loss: 0.920066] [G loss: 1.447879] [D real: 0.746120] [D fake: 0.368290]\n",
      "[Epoch 45/50] [Batch 899/938] [D loss: 0.900949] [G loss: 1.810930] [D real: 0.694689] [D fake: 0.292194]\n",
      "[Epoch 46/50] [Batch 99/938] [D loss: 0.931617] [G loss: 1.528009] [D real: 0.670601] [D fake: 0.301757]\n",
      "[Epoch 46/50] [Batch 199/938] [D loss: 1.052852] [G loss: 1.900161] [D real: 0.722106] [D fake: 0.414488]\n",
      "[Epoch 46/50] [Batch 299/938] [D loss: 0.856692] [G loss: 1.743413] [D real: 0.749411] [D fake: 0.355238]\n",
      "[Epoch 46/50] [Batch 399/938] [D loss: 0.921947] [G loss: 1.422383] [D real: 0.711285] [D fake: 0.341403]\n",
      "[Epoch 46/50] [Batch 499/938] [D loss: 1.313393] [G loss: 1.842573] [D real: 0.820339] [D fake: 0.557965]\n",
      "[Epoch 46/50] [Batch 599/938] [D loss: 1.011101] [G loss: 1.922293] [D real: 0.787551] [D fake: 0.429074]\n",
      "[Epoch 46/50] [Batch 699/938] [D loss: 0.841098] [G loss: 1.209525] [D real: 0.632937] [D fake: 0.201084]\n",
      "[Epoch 46/50] [Batch 799/938] [D loss: 0.857971] [G loss: 1.661078] [D real: 0.650545] [D fake: 0.252789]\n",
      "[Epoch 46/50] [Batch 899/938] [D loss: 0.841266] [G loss: 1.537403] [D real: 0.741949] [D fake: 0.329425]\n",
      "[Epoch 47/50] [Batch 99/938] [D loss: 0.756640] [G loss: 1.389430] [D real: 0.739923] [D fake: 0.280656]\n",
      "[Epoch 47/50] [Batch 199/938] [D loss: 0.936060] [G loss: 1.180127] [D real: 0.642792] [D fake: 0.276859]\n",
      "[Epoch 47/50] [Batch 299/938] [D loss: 0.836986] [G loss: 1.551770] [D real: 0.745202] [D fake: 0.309450]\n",
      "[Epoch 47/50] [Batch 399/938] [D loss: 0.941226] [G loss: 2.102375] [D real: 0.756448] [D fake: 0.416946]\n",
      "[Epoch 47/50] [Batch 499/938] [D loss: 0.846286] [G loss: 1.124397] [D real: 0.613124] [D fake: 0.193637]\n",
      "[Epoch 47/50] [Batch 599/938] [D loss: 1.226512] [G loss: 2.274374] [D real: 0.851092] [D fake: 0.578987]\n",
      "[Epoch 47/50] [Batch 699/938] [D loss: 0.844091] [G loss: 2.098285] [D real: 0.797239] [D fake: 0.372913]\n",
      "[Epoch 47/50] [Batch 799/938] [D loss: 0.809862] [G loss: 1.321720] [D real: 0.688485] [D fake: 0.269186]\n",
      "[Epoch 47/50] [Batch 899/938] [D loss: 0.809950] [G loss: 1.489237] [D real: 0.726346] [D fake: 0.288433]\n",
      "[Epoch 48/50] [Batch 99/938] [D loss: 0.686341] [G loss: 1.475377] [D real: 0.728955] [D fake: 0.228990]\n",
      "[Epoch 48/50] [Batch 199/938] [D loss: 0.823539] [G loss: 1.513274] [D real: 0.744420] [D fake: 0.325147]\n",
      "[Epoch 48/50] [Batch 299/938] [D loss: 1.056263] [G loss: 1.086715] [D real: 0.601779] [D fake: 0.285253]\n",
      "[Epoch 48/50] [Batch 399/938] [D loss: 1.025053] [G loss: 1.608612] [D real: 0.708154] [D fake: 0.389036]\n",
      "[Epoch 48/50] [Batch 499/938] [D loss: 0.826788] [G loss: 1.532743] [D real: 0.708048] [D fake: 0.289725]\n",
      "[Epoch 48/50] [Batch 599/938] [D loss: 1.030626] [G loss: 1.174569] [D real: 0.604371] [D fake: 0.228374]\n",
      "[Epoch 48/50] [Batch 699/938] [D loss: 0.979014] [G loss: 1.655726] [D real: 0.829297] [D fake: 0.466578]\n",
      "[Epoch 48/50] [Batch 799/938] [D loss: 0.822509] [G loss: 1.381917] [D real: 0.683930] [D fake: 0.234838]\n",
      "[Epoch 48/50] [Batch 899/938] [D loss: 0.788834] [G loss: 1.424368] [D real: 0.761313] [D fake: 0.325454]\n",
      "[Epoch 49/50] [Batch 99/938] [D loss: 0.845811] [G loss: 1.188638] [D real: 0.659822] [D fake: 0.244031]\n",
      "[Epoch 49/50] [Batch 199/938] [D loss: 0.744286] [G loss: 1.960347] [D real: 0.803068] [D fake: 0.348954]\n",
      "[Epoch 49/50] [Batch 299/938] [D loss: 0.932643] [G loss: 1.325927] [D real: 0.673306] [D fake: 0.314272]\n",
      "[Epoch 49/50] [Batch 399/938] [D loss: 0.797092] [G loss: 1.566101] [D real: 0.815949] [D fake: 0.387285]\n",
      "[Epoch 49/50] [Batch 499/938] [D loss: 0.935683] [G loss: 1.964920] [D real: 0.737230] [D fake: 0.353584]\n",
      "[Epoch 49/50] [Batch 599/938] [D loss: 0.896155] [G loss: 1.286186] [D real: 0.628217] [D fake: 0.200258]\n",
      "[Epoch 49/50] [Batch 699/938] [D loss: 0.737871] [G loss: 1.533297] [D real: 0.689302] [D fake: 0.227947]\n",
      "[Epoch 49/50] [Batch 799/938] [D loss: 0.895830] [G loss: 1.817544] [D real: 0.715992] [D fake: 0.344601]\n",
      "[Epoch 49/50] [Batch 899/938] [D loss: 1.011860] [G loss: 2.276277] [D real: 0.766816] [D fake: 0.422015]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "# Training\n",
    "# ----------\n",
    "# 进行多个epoch的训练\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "n_epochs = 50\n",
    "sample_interval = 500\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # 训练判别器\n",
    "        imgs = imgs.view(imgs.size(0), -1)\n",
    "        # 将tensor变成Variable放入计算图中，tensor变成variable之后才能进行反向传播求梯度\n",
    "        real_img = Variable(imgs).cuda()\n",
    "        real_label = Variable(torch.ones(imgs.size(0), 1)\n",
    "                              ).cuda()  # 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(imgs.size(0), 1)\n",
    "                              ).cuda()  # 定义假的图片的label为0\n",
    "\n",
    "        # Train Discriminator\n",
    "        # 计算真实图片的损失\n",
    "        real_out = discriminator(real_img)\n",
    "        loss_real_D = criterion(real_out, real_label)\n",
    "        real_scores = real_out\n",
    "        # 计算假的图片的损失\n",
    "        # detach(): 从当前计算图中分离下来避免梯度传到G，因为G不用更新\n",
    "        z = Variable(torch.randn(imgs.size(0), latent_dim)).cuda()\n",
    "        fake_img = generator(z).detach()  # 随机噪声放入生成网络中，生成一张假的图片。\n",
    "        fake_out = discriminator(fake_img)\n",
    "        loss_fake_D = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out\n",
    "        # 损失函数和优化\n",
    "        loss_D = loss_real_D + loss_fake_D\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = Variable(torch.randn(imgs.size(0), latent_dim)).cuda()\n",
    "        fake_img = generator(z)\n",
    "        output = discriminator(fake_img)\n",
    "        # 损失函数和优化\n",
    "        loss_G = criterion(output, real_label)\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 打印训练过程中的日志\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [D real: %f] [D fake: %f]\"\n",
    "                % (epoch, n_epochs, i, len(dataloader), loss_D.item(), loss_G.item(), real_scores.data.mean(), fake_scores.data.mean())\n",
    "            )\n",
    "        # 保存训练过程中的图像\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            save_image(fake_img.data[:25], \"./images/gan/%d.png\" %\n",
    "                       batches_done, nrow=5, normalize=True)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(generator.state_dict(), './save/gan/generator.pth')\n",
    "torch.save(discriminator.state_dict(), './save/gan/discriminator.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aa3b3d4993e6b35bfebb07d3b44d18e61525325b0a1965d690fdc28e02ac980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
